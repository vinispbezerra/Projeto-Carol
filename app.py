import streamlit as st
import pandas as pd
import plotly.express as px
from prophet import Prophet
from prophet.plot import plot_plotly
from prophet.diagnostics import cross_validation, performance_metrics
import numpy as np 
import warnings
import logging
from matplotlib import pyplot as plt

# Configura√ß√µes iniciais
st.set_page_config(page_title="An√°lise de Importa√ß√£o PMMA", layout="wide")

# Configurar logging do Prophet para silenciar warnings excessivos
logging.getLogger('cmdstanpy').setLevel(logging.WARNING)
warnings.filterwarnings("ignore", message="The behavior of DataFrame concatenation with empty or all-NA entries is deprecated")


st.title("üìä An√°lise de Importa√ß√£o - PMMA")

# --- Leitura do Arquivo (Suporte a Excel e CSV) ---
uploaded_file = st.file_uploader("Carregue o arquivo de dados (Excel ou CSV)", type=["xlsx", "csv"])
if uploaded_file:
    file_extension = uploaded_file.name.split(".")[-1].lower()
    df = pd.DataFrame()
    
    try:
        if file_extension == "xlsx":
            try:
                # Tenta ler a aba 'Sheet1', mas fallback para a primeira aba se n√£o existir
                df = pd.read_excel(uploaded_file, sheet_name="Sheet1")
            except ValueError:
                st.warning("A aba 'Sheet1' n√£o foi encontrada. Lendo a primeira aba da planilha.")
                df = pd.read_excel(uploaded_file, sheet_name=0)
        
        elif file_extension == "csv":
            # Lendo CSV com infer√™ncia de delimitador
            df = pd.read_csv(uploaded_file, sep=None, engine='python', encoding='utf-8', on_bad_lines='skip')
            
        else:
            st.error("Tipo de arquivo n√£o suportado.")
            st.stop()
            
    except Exception as e:
        st.error(f"Erro ao ler o arquivo: {e}")
        st.stop()

    # --- Normaliza√ß√£o e Mapeamento de Colunas (Adaptado para a nova planilha) ---
    # 1. Normaliza os nomes de coluna removendo espa√ßos laterais
    df.columns = [col.strip() for col in df.columns]

    column_mapping = {
        # Colunas Chave para Agrega√ß√£o
        "Peso l√≠quido": "Peso",
        "VALOR FOB ESTIMADO TOTAL": "Valor_FOB",
        "VALOR CIF TOTAL": "Valor_CIF",
        "QTD Estat√≠stica": "Qtd_Estat√≠stica",
        "Qtd. de opera√ß√µes estimada": "Qtd_Estat√≠stica", # Causa do conflito
        
        # Colunas de Agrupamento
        "Descri√ß√£o produto": "Produto",
        "PAIS DE ORIGEM": "Pa√≠s",
        "Pa√≠s de aquisi√ß√£o": "Pa√≠s_Aquisi√ß√£o",
        "URF de Entrada": "URF_Entrada",
        "PROV√ÅVEL IMPORTADOR": "Importador",
        "PROV√ÅVEL EXPORTADOR": "Exportador",
        "NCM's": "NCM",
        "NCM": "NCM", 
        "MODAL": "Modal",
        "Incoterm": "Incoterm", 
        
        # Colunas Unit√°rias e Secund√°rias
        "Valor CIF Unit√°rio": "CIF_Unit√°rio",
        "Valor FOB Estimado Unit√°rio": "FOB_Unit√°rio", 
    }
    
    renamed_cols = {}
    for k_orig, v_new in column_mapping.items():
        if k_orig in df.columns:
            renamed_cols[k_orig] = v_new

    # --- CR√çTICO: RESOLVER CONFLITO DE DUPLICA√á√ÉO DE COLUNAS ANTES DE RENOMEAR ---
    
    # Colunas originais que mapeiam para o mesmo destino "Qtd_Estat√≠stica"
    col_qte_est_1 = "QTD Estat√≠stica"
    col_qte_est_2 = "Qtd. de opera√ß√µes estimada"
    
    # Se ambas as colunas originais estiverem presentes, removemos a de nome mais simples (menos descritivo)
    if col_qte_est_1 in df.columns and col_qte_est_2 in df.columns:
        try:
            # Dropa a primeira coluna, mantendo apenas a segunda, para evitar a duplica√ß√£o no rename
            df.drop(columns=[col_qte_est_1], inplace=True)
            # Remove a coluna da lista de renomea√ß√£o para evitar erro
            if col_qte_est_1 in renamed_cols:
                del renamed_cols[col_qte_est_1]
            st.warning(f"Conflito de colunas resolvido: '{col_qte_est_1}' foi removida em favor de '{col_qte_est_2}'.")
        except Exception as e:
            st.error(f"Erro ao tentar resolver o conflito de colunas: {e}")

    # 2. Executa a renomea√ß√£o com as colunas restantes
    df = df.rename(columns=renamed_cols)

    # 3. NOVO PASSO CR√çTICO: REMOVER COLUNAS DUPLICADAS RESIDUAIS GERADAS PELO MAPPEAMENTO
    # Este passo √© a garantia final para o PyArrow/Streamlit.
    if not df.empty:
        df = df.loc[:, ~df.columns.duplicated(keep='first')]


    # --- Tratamento da data (Robusto) ---
    try:
        def safe_to_datetime(dt_val):
            if pd.isna(dt_val):
                return pd.NaT
            
            dt_str = str(dt_val)
            
            if '-' in dt_str or '/' in dt_str:
                return pd.to_datetime(dt_str, errors='coerce')
            
            try:
                # Se for n√∫mero (float ou string) tenta converter para YYYYMM (ex: 202507)
                if '.' in dt_str and dt_str.replace('.', '', 1).isdigit():
                    dt_str = dt_str.split('.')[0]
                    
                if dt_str.isdigit() and len(dt_str) >= 6:
                     # Tenta o formato YYYYMM
                     return pd.to_datetime(dt_str, format="%Y%m", errors='coerce')
            except:
                pass
            return pd.NaT
        
        if "ANO/M√äS" in df.columns:
            df["ANO/M√äS"] = df["ANO/M√äS"].apply(safe_to_datetime)
            df.dropna(subset=["ANO/M√äS"], inplace=True)
            
            if not pd.api.types.is_datetime64_any_dtype(df["ANO/M√äS"]):
                df["ANO/M√äS"] = pd.to_datetime(df["ANO/M√äS"], errors='coerce')
                df.dropna(subset=["ANO/M√äS"], inplace=True)
        else:
             st.error("A coluna 'ANO/M√äS' essencial para a an√°lise de s√©rie temporal n√£o foi encontrada.")
             st.stop()
             
    except Exception as e:
        st.error(f"Erro no tratamento da coluna 'ANO/M√äS'. Verifique se as datas est√£o no formato YYYYMM ou YYYY-MM-DD. Erro: {e}")
        st.stop()

    # --- Verifica√ß√£o e Backfill de Colunas Essenciais ---
    if "Peso" not in df.columns:
        st.error("A coluna 'Peso' (mapeada de 'Peso l√≠quido') essencial para a an√°lise n√£o foi encontrada.")
        st.stop()

    for col in ["Valor_FOB", "Valor_CIF", "Qtd_Estat√≠stica"]:
        if col not in df.columns:
            df[col] = 0.0
            st.warning(f"A coluna '{col}' estava ausente e foi preenchida com zero para evitar erros de processamento.")
        
    # --- Convers√£o das colunas de valor para num√©rico (Lida com o formato brasileiro) ---
    numeric_cols = ["Peso", "Valor_FOB", "Valor_CIF", "Qtd_Estat√≠stica", "CIF_Unit√°rio", "FOB_Unit√°rio"]
    for col in numeric_cols:
        if col in df.columns:
            try:
                # 1. Usa .copy() para garantir que a c√≥pia para limpeza n√£o gere warnings
                data_to_clean = pd.Series(df[col]).copy()
                
                # 2. Converte para string
                col_data = data_to_clean.astype(str)
                
                # 3. Refor√ßo de limpeza: Remove pontos (milhar), substitui v√≠rgulas por pontos (decimal)
                col_data = (
                    col_data
                    .str.replace(".", "", regex=False)
                    .str.replace(",", ".", regex=False)
                    .str.replace(" ", "", regex=False) # remove espa√ßos em branco residuais
                )
                
                # 4. Converte para num√©rico. Qualquer falha (incluindo 'nan') vira NaN
                df[col] = pd.to_numeric(col_data, errors='coerce')
                
                # 5. Preenche NaN com 0 para o c√°lculo e define o tipo como float
                df[col] = df[col].fillna(0).astype(float)
                
            except Exception as e:
                # Log do erro de limpeza, e tenta fallback.
                st.warning(f"Erro DETALHADO ao processar a coluna {col} na limpeza: {e}. Executando fallback robusto.")
                try:
                    # Fallback com Series() for√ßado para evitar o TypeError
                    df[col] = pd.to_numeric(pd.Series(df[col]), errors='coerce').fillna(0).astype(float)
                except Exception as fallback_e:
                    st.error(f"Erro CR√çTICO no Fallback para a coluna {col}: {fallback_e}. Esta coluna ser√° tratada como zero para permitir a continuidade.")
                    df[col] = 0.0 # Definir como 0.0 se tudo falhar

    # --- Menu lateral ---
    menu = st.sidebar.radio("Escolha a an√°lise:", ["An√°lise Hist√≥rica", "Previs√£o"])

    # =====================================================
    # AN√ÅLISE HIST√ìRICA
    # =====================================================
    if menu == "An√°lise Hist√≥rica":
        st.subheader("üìà An√°lise Hist√≥rica")

        # --- Filtros e Agrupamento ---
        st.subheader("‚öôÔ∏è Filtros e Agrupamento")
        
        col1, col2 = st.columns(2)
        
        # Filtros
        with col1:
            produtos_options = df["Produto"].dropna().unique() if "Produto" in df.columns else []
            produtos = st.multiselect("Selecione os produtos:", produtos_options)
        
        with col2:
            paises_options = df["Pa√≠s"].dropna().unique() if "Pa√≠s" in df.columns else []
            paises = st.multiselect("Selecione os pa√≠ses:", paises_options)

        df_filtrado = df.copy()
        if produtos and "Produto" in df_filtrado.columns:
            df_filtrado = df_filtrado[df_filtrado["Produto"].isin(produtos)]
        if paises and "Pa√≠s" in df_filtrado.columns:
            df_filtrado = df_filtrado[df_filtrado["Pa√≠s"].isin(paises)]

        # Seletor de Agrupamento
        group_by_options = ["Nenhum"] + [
            col for col in ["Importador", "Exportador", "Pa√≠s_Aquisi√ß√£o", "NCM", "Modal", "URF_Entrada", "Incoterm"] 
            if col in df.columns
        ]
        
        group_by_col = st.selectbox(
            "Agrupar evolu√ß√£o por:", 
            group_by_options
        )

        if df_filtrado.empty:
            st.warning("Nenhum dado encontrado com os filtros selecionados.")
        else:
            # Etapa 1: Preparar o DataFrame para Agrupamento e Copiar
            df_groupby_ready = df_filtrado.copy()

            # Etapa 2: Configurar o Agrupamento
            group_cols = ["ANO/M√äS"]
            color_param = None
            if group_by_col != "Nenhum" and group_by_col in df_groupby_ready.columns:
                group_cols.append(group_by_col)
                df_groupby_ready[group_by_col] = df_groupby_ready[group_by_col].astype(str).fillna("N√£o Informado")
                color_param = group_by_col
            elif group_by_col != "Nenhum":
                 st.warning(f"A coluna de agrupamento '{group_by_col}' n√£o foi encontrada.")
                 group_by_col = "Nenhum"
                 color_param = None
            
            # Etapa 3: Configurar o Dicion√°rio de Agrega√ß√£o
            agg_dict = {
                "Peso": 'sum',
                "Valor_FOB": 'sum',
                "Valor_CIF": 'sum'
            }
            if "Qtd_Estat√≠stica" in df_groupby_ready.columns:
                agg_dict["Qtd_Estat√≠stica"] = 'sum'

            # --- ESTRAT√âGIA DE MERGE COM LIMPEZA DE COLUNAS ---
            
            # 1. Colunas de Agrupamento + Colunas de Agrega√ß√£o
            cols_to_select = group_cols + list(agg_dict.keys())
            
            # 2. Seleciona apenas as colunas dispon√≠veis no DataFrame e faz a limpeza m√°xima
            available_cols_for_agg = [col for col in cols_to_select if col in df_groupby_ready.columns]
            df_final_for_agg = df_groupby_ready[available_cols_for_agg].copy()
            df_final_for_agg = df_final_for_agg.reset_index(drop=True) 

            # 3. Cria o objeto GroupBy
            grouped_obj = df_final_for_agg.groupby(group_cols, as_index=False)
            
            # 4. Agrega a primeira coluna para iniciar o DataFrame agrupado
            first_agg_col = list(agg_dict.keys())[0]
            
            # DataFrame inicial: Cont√©m as colunas de agrupamento + a primeira agrega√ß√£o
            agrupado_agg = grouped_obj[first_agg_col].agg('sum').reset_index()

            # CR√çTICO: Limpar o DataFrame inicial de quaisquer colunas esp√∫rias (como 'index' ou 'level_0')
            agrupado_agg = agrupado_agg[group_cols + [first_agg_col]].copy()

            # 5. Itera sobre o restante das colunas e junta (merge) ao DataFrame principal
            for col_to_agg in list(agg_dict.keys())[1:]: # Ignora a primeira
                func = agg_dict[col_to_agg]
                
                # 5a. Agrega a coluna restante e garante que o index seja resetado.
                temp_result = grouped_obj[col_to_agg].agg(func).reset_index()
                
                # CR√çTICO: Manter APENAS as colunas de join (group_cols) e a coluna agregada (col_to_agg)
                temp_result = temp_result[group_cols + [col_to_agg]]
                
                # 5b. Junta (merge) o resultado ao DataFrame principal (agrupado_agg)
                agrupado_agg = agrupado_agg.merge(
                    temp_result, 
                    on=group_cols, 
                    how='left'
                )
            
            # PASSO DE SEGURAN√áA: LIMPEZA DE COLUNAS DUPLICADAS AP√ìS AGREGA√á√ÉO
            # Para evitar o erro narwhals/plotly.
            agrupado_agg = agrupado_agg.loc[:, ~agrupado_agg.columns.duplicated(keep='first')]


            # Garantir que a coluna 'ANO/M√äS' seja datetime para o Plotly
            agrupado_agg["ANO/M√äS"] = pd.to_datetime(agrupado_agg["ANO/M√äS"])
            
            # --- Plotagem de Quantidades ---
            st.subheader("üì¶ Evolu√ß√£o Quantidades")
            
            qty_cols = ["Peso"]
            
            if "Qtd_Estat√≠stica" in agrupado_agg.columns:
                try:
                    total_sum = agrupado_agg["Qtd_Estat√≠stica"].sum()
                    
                    if isinstance(total_sum, pd.Series) or isinstance(total_sum, np.ndarray):
                        if total_sum.item() > 0:
                            qty_cols.append("Qtd_Estat√≠stica")
                    elif total_sum > 0:
                        qty_cols.append("Qtd_Estat√≠stica")
                        
                except Exception:
                    st.warning("N√£o foi poss√≠vel validar a soma total de 'Qtd_Estat√≠stica'. A coluna foi ignorada na plotagem de Quantidades.")
            
            
            if color_param:
                df_melted_qtd = agrupado_agg.melt(
                    id_vars=group_cols, 
                    value_vars=qty_cols, 
                    var_name="M√©trica", 
                    value_name="Quantidade"
                )
                fig_qtd = px.line(
                    df_melted_qtd,
                    x="ANO/M√äS",
                    y="Quantidade",
                    color=color_param,
                    line_dash="M√©trica",
                    labels={"M√©trica": "Tipo de Quantidade", "ANO/M√äS": "Data"},
                    markers=True,
                    title=f"Evolu√ß√£o Mensal: Quantidades por {group_by_col}"
                )
            else:
                fig_qtd = px.line(
                    agrupado_agg,
                    x="ANO/M√äS",
                    y=qty_cols,
                    labels={"value": "Quantidade", "variable": "M√©trica", "ANO/M√äS": "Data"},
                    markers=True,
                    title="Evolu√ß√£o Mensal: Quantidades (Peso L√≠quido vs. Estat√≠stica)"
                )

            fig_qtd.update_layout(hovermode="x unified")
            st.plotly_chart(fig_qtd, use_container_width=True)

            # --- Plotagem de Valores ---
            st.subheader("üí∞ Evolu√ß√£o Valores")
            
            value_cols = []
            if "Valor_FOB" in agrupado_agg.columns and agrupado_agg["Valor_FOB"].sum() > 0:
                 value_cols.append("Valor_FOB")
            if "Valor_CIF" in agrupado_agg.columns and agrupado_agg["Valor_CIF"].sum() > 0:
                 value_cols.append("Valor_CIF")
            
            if not value_cols:
                st.info("As colunas 'Valor_FOB' e 'Valor_CIF' est√£o ausentes ou cont√™m apenas zeros. N√£o √© poss√≠vel plotar a Evolu√ß√£o de Valores.")
            else:
                if color_param:
                    df_melted_valor = agrupado_agg.melt(
                        id_vars=group_cols, 
                        value_vars=value_cols, 
                        var_name="M√©trica", 
                        value_name="Valor (US$)"
                    )
                    fig_valor = px.line(
                        df_melted_valor,
                        x="ANO/M√äS",
                        y="Valor (US$)",
                        color=color_param,
                        line_dash="M√©trica",
                        labels={"M√©trica": "Tipo de Valor", "ANO/M√äS": "Data"},
                        markers=True,
                        title=f"Evolu√ß√£o Mensal: Valor FOB e CIF por {group_by_col}"
                    )
                else:
                    fig_valor = px.line(
                        agrupado_agg,
                        x="ANO/M√äS",
                        y=value_cols,
                        labels={"value": "Valor (US$)", "variable": "M√©trica", "ANO/M√äS": "Data"},
                        markers=True,
                        title="Evolu√ß√£o Mensal: Valor FOB vs. Valor CIF"
                    )
    
                fig_valor.update_layout(hovermode="x unified")
                st.plotly_chart(fig_valor, use_container_width=True)

            # --- Estat√≠sticas ---
            st.subheader("üìå Estat√≠sticas Resumidas")
            
            if not agrupado_agg.empty:
                desc_df = agrupado_agg.describe().T
                formatted_desc = desc_df.copy()
                for col in formatted_desc.columns:
                     if pd.api.types.is_numeric_dtype(formatted_desc[col]):
                        formatted_desc[col] = formatted_desc[col].apply(lambda x: f'{x:,.2f}')
                        
                st.dataframe(formatted_desc, use_container_width=True)
            else:
                 st.info("N√£o h√° dados para gerar as estat√≠sticas resumidas.")


            # --- Visualiza√ß√£o de Dados Detalhados ---
            st.subheader("üîé Visualiza√ß√£o dos Dados Detalhados")
            
            display_cols = [
                "ANO/M√äS", "Produto", "Pa√≠s", "Peso", "Valor_FOB", "Valor_CIF", "Qtd_Estat√≠stica",
                "FOB_Unit√°rio", "CIF_Unit√°rio", "Pa√≠s_Aquisi√ß√£o", "URF_Entrada", "Importador", "NCM", "Modal", "Exportador", "Incoterm"
            ]
            
            # Filtra apenas as colunas dispon√≠veis no DataFrame filtrado e deduplicado
            # df_filtrado j√° √© uma c√≥pia de df, que foi deduplicado no in√≠cio
            available_cols = [col for col in display_cols if col in df_filtrado.columns]

            st.dataframe(
                df_filtrado[available_cols].sort_values(by="ANO/M√äS", ascending=False), 
                use_container_width=True
            )

    # =====================================================
    # PREVIS√ÉO COM PROPHET
    # =====================================================
    elif menu == "Previs√£o":
        st.subheader("üîÆ Previs√£o de S√©ries Temporais")

        # Define as m√©tricas dispon√≠veis (apenas as que t√™m valores > 0)
        available_metrics = [col for col in ["Peso", "Qtd_Estat√≠stica", "Valor_FOB", "Valor_CIF"] if col in df.columns and df[col].sum() > 0]
        
        if not available_metrics:
            st.error("Nenhuma coluna num√©rica com valores maiores que zero foi encontrada para realizar a previs√£o. Por favor, verifique as colunas de Peso, Valor FOB ou Valor CIF.")
            st.stop()
            
        # Escolher m√©trica
        metrica = st.selectbox(
            "Selecione a m√©trica para previs√£o:",
            available_metrics
        )
        
        # Par√¢metros do Prophet
        st.markdown("---")
        st.subheader("üõ†Ô∏è Ajustes do Modelo Prophet (Hiperpar√¢metros)")

        col_params_1, col_params_2 = st.columns(2)
        
        with col_params_1:
            seasonality_mode = st.selectbox(
                "Modo de Sazonalidade:",
                ["multiplicative", "additive"],
                index=0,
                help="Multiplicativo: Sazonalidade cresce com a tend√™ncia. Aditivo: Sazonalidade constante."
            )
        with col_params_2:
            changepoint_prior_scale = st.slider(
                "Prior Scale (Flexibilidade da Tend√™ncia):",
                min_value=0.001,
                max_value=0.5,
                value=0.05,
                step=0.005,
                help="Maior valor = Modelo mais flex√≠vel/propenso a overfitting. Menor valor = Modelo mais suave."
            )

        # Agrupamento mensal
        agg_dict = {m: 'sum' for m in ["Peso", "Qtd_Estat√≠stica", "Valor_FOB", "Valor_CIF"] if m in df.columns}
        # Agrupamento simples para a Previs√£o (n√£o usa os filtros de agrupamento)
        agrupado = df.groupby("ANO/M√äS").agg(agg_dict).reset_index()

        if agrupado.empty or metrica not in agrupado.columns:
            st.warning("N√£o h√° dados de s√©rie temporal suficientes ou a m√©trica selecionada n√£o est√° dispon√≠vel ap√≥s o agrupamento.")
            st.stop()
        else:
            # Preparar dados para o Prophet
            df_prophet = agrupado[["ANO/M√äS", metrica]].rename(columns={"ANO/M√äS": "ds", metrica: "y"})
            df_prophet.dropna(inplace=True)

            if len(df_prophet) < 2:
                st.error("Dados insuficientes para a previs√£o. Pelo menos 2 pontos temporais s√£o necess√°rios.")
                st.stop()

            # --- Treinamento do Modelo ---
            with st.spinner(f"Treinando o modelo Prophet com a m√©trica {metrica}..."):
                model = Prophet(
                    seasonality_mode=seasonality_mode,
                    changepoint_prior_scale=changepoint_prior_scale,
                    daily_seasonality=False,
                    weekly_seasonality=False,
                    yearly_seasonality=True 
                )
                try:
                    model.fit(df_prophet)
                except Exception as e:
                    st.error(f"Erro ao treinar o modelo. Verifique a qualidade dos dados. Erro: {e}")
                    st.stop()


            # --- Previs√£o ---
            periods = st.slider("Selecione o n√∫mero de meses para a previs√£o:", min_value=1, max_value=24, value=6)
            future = model.make_future_dataframe(periods=periods, freq="M")
            forecast = model.predict(future)

            # Plot interativo
            st.subheader(f"Gr√°fico de Previs√£o para {metrica}")
            fig_forecast = plot_plotly(model, forecast)
            fig_forecast.update_layout(
                title=f"Previs√£o de Importa√ß√£o - {metrica}",
                xaxis_title="Data",
                yaxis_title=f"{metrica} (Valor Previsto)",
                hovermode="x unified"
            )
            st.plotly_chart(fig_forecast, use_container_width=True)

            st.subheader("üìå Componentes da Previs√£o")
            st.markdown("Os gr√°ficos abaixo mostram a Tend√™ncia, Sazonalidade Anual e Pontos de Mudan√ßa detectados pelo modelo.")
            
            # Usando Matplotlib para plotar componentes
            fig_components = model.plot_components(forecast)
            st.pyplot(fig_components)
            plt.close(fig_components)
            
            st.subheader("üìå Tabela de Previs√£o")
            # Mostrar os √∫ltimos registros (hist√≥rico + previs√£o)
            st.dataframe(
                forecast[["ds", "yhat", "yhat_lower", "yhat_upper"]]
                .rename(columns={"ds": "Data", "yhat": "Previs√£o", "yhat_lower": "Limite Inferior", "yhat_upper": "Limite Superior"})
                .tail(periods + 1)
                .style.format(
                    {
                        "Previs√£o": "{:,.2f}",
                        "Limite Inferior": "{:,.2f}",
                        "Limite Superior": "{:,.2f}",
                        "Data": lambda x: x.strftime('%Y-%m-%d')
                    }
                ),
                use_container_width=True
            )

            # --- Cross-Validation ---
            st.markdown("---")
            st.subheader("üß™ Diagn√≥stico: Avalia√ß√£o de Performance")
            
            min_data_points = 12 * 3
            if len(df_prophet) < min_data_points:
                st.info(f"O modelo Prophet sugere pelo menos {min_data_points} pontos de dados (meses) para uma valida√ß√£o cruzada robusta. Voc√™ tem apenas {len(df_prophet)}.")
            
            perform_cv = st.checkbox("Executar Valida√ß√£o Cruzada (Cross-Validation)?", value=False)
            
            if perform_cv:
                
                initial_months = max(int(len(df_prophet) * 0.5), 24)
                
                if initial_months >= len(df_prophet) - periods:
                    initial_months = max(len(df_prophet) - periods, 12)
                    if initial_months < 12:
                         st.warning("Dados insuficientes para uma CV significativa. Tentando com o m√≠nimo poss√≠vel.")
                         initial_months = max(len(df_prophet) - 3, 3)
                         
                h = f'{periods} months'
                initial = f'{initial_months} months'
                period_months = min(12, int((len(df_prophet) - initial_months) / 2))
                period = f'{period_months} months' if period_months > 0 else '6 months'


                st.info(f"Par√¢metros da Valida√ß√£o Cruzada: Initial={initial}, Period={period}, Horizon={h}")
                
                try:
                    with st.spinner("Executando a Valida√ß√£o Cruzada (pode demorar)..."):
                        with warnings.catch_warnings():
                            warnings.simplefilter("ignore")
                            df_cv = cross_validation(
                                model, 
                                initial=initial, 
                                period=period, 
                                horizon=h,
                                parallel="processes"
                            )
                        
                        df_p = performance_metrics(df_cv)

                    st.success("Valida√ß√£o Cruzada Conclu√≠da!")
                    
                    st.markdown("M√©tricas de performance m√©dias ao longo do horizonte de previs√£o:")
                    st.dataframe(df_p[['horizon', 'rmse', 'mae', 'mape', 'mdape']].head(), use_container_width=True)

                    st.markdown("O RMSE (Root Mean Squared Error) e MAE (Mean Absolute Error) devem ser os menores poss√≠veis. O MAPE (Mean Absolute Percentage Error) indica o erro percentual (idealmente < 10%).")
                    
                    fig_perf = px.line(
                        df_p,
                        x="horizon",
                        y=["rmse", "mape"],
                        title="Performance do Modelo (RMSE e MAPE) por Horizonte de Previs√£o",
                        labels={"value": "M√©trica", "horizon": "Horizonte de Previs√£o"}
                    )
                    st.plotly_chart(fig_perf, use_container_width=True)

                except ValueError as e:
                    st.error(f"Erro ao executar a Valida√ß√£o Cruzada. Verifique se a s√©rie temporal √© longa o suficiente para os par√¢metros de Initial={initial}, Period={period} e Horizon={h}. Erro: {e}")
                except Exception as e:
                    st.error(f"Ocorreu um erro inesperado durante a Valida√ß√£o Cruzada: {e}")
            else:
                st.info("A Valida√ß√£o Cruzada testa a precis√£o do modelo usando dados hist√≥ricos, fornecendo m√©tricas de erro como RMSE e MAPE.")

else:
    # Mensagem de instru√ß√£o
    st.info("‚¨ÜÔ∏è Fa√ßa upload da planilha para iniciar a an√°lise.")
    st.markdown("""
        **Estrutura esperada da planilha (colunas essenciais para o App funcionar):**
        - `ANO/M√äS`: Datas no formato `YYYYMM` (Ex: 202301, 202302) ou `YYYY-MM-DD`.
        - `Descri√ß√£o produto`: Nome do produto.
        - `PAIS DE ORIGEM` ou `PA√çS DE ORIGEM`: Nome do pa√≠s.
        - **`Peso l√≠quido` (ESSENCIAL)**: Peso da importa√ß√£o.
        - `VALOR FOB ESTIMADO TOTAL`: Valor FOB total.
        - `VALOR CIF TOTAL`: Valor CIF total.
        - `QTD Estat√≠stica` ou `Qtd. de opera√ß√µes estimada`: Quantidade estat√≠stica.
        
        **Colunas adicionais suportadas (para agrupamento e detalhamento):**
        - `Incoterm` (novo para agrupamento), `Valor CIF Unit√°rio`, `Valor FOB Estimado Unit√°rio`, `Pa√≠s de aquisi√ß√£o`, `URF de Entrada`, `PROV√ÅVEL IMPORTADOR`, `NCM`, `MODAL`, `PROV√ÅVEL EXPORTADOR`
    """)